{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemanticMatch: AI-Powered Product Intelligence Using Vector Search\\n",
    "## BigQuery AI Hackathon - Approach 2: The Semantic Detective üïµÔ∏è‚Äç‚ôÄÔ∏è\\n",
    "\\n",
    "This notebook demonstrates how vector search solves critical e-commerce problems:\\n",
    "- **Duplicate Detection**: Find the same product listed multiple times\\n",
    "- **Semantic Search**: Understand meaning, not just keywords\\n",
    "- **Smart Substitutes**: Find truly similar products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: Keywords Fail, Meaning Matters\\n",
    "\\n",
    "Traditional search fails because:\\n",
    "- Same product, different descriptions (\\\"Nike Air Max\\\" vs \\\"Nike Airmax Shoes\\\")\\n",
    "- Missing inventory due to duplicates (5-10% typical)\\n",
    "- Poor substitutes (\\\"out of stock\\\" = lost sale)\\n",
    "- Frustrated customers can't find what they want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Import our custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from vector_engine import BigQueryVectorEngine, get_vector_engine\n",
    "from duplicate_detector import DuplicateDetector, DuplicateCandidate\n",
    "from embedding_generator import EmbeddingGenerator\n",
    "from similarity_search import SimilaritySearch, SearchStrategy\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = 'your-project-id'  # Replace with your project\n",
    "DATASET_ID = 'semantic_demo'\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "# Initialize components\n",
    "print(\"Initializing Semantic Detection Engine...\")\n",
    "vector_engine = get_vector_engine(PROJECT_ID, DATASET_ID)\n",
    "duplicate_detector = DuplicateDetector()\n",
    "embedding_generator = EmbeddingGenerator()\n",
    "similarity_search = SimilaritySearch(PROJECT_ID, DATASET_ID)\n",
    "\n",
    "print(\"‚úÖ All components initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Product Catalog with Hidden Duplicates\\n",
    "\\n",
    "Let's create a realistic catalog with duplicate products that traditional search would miss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a catalog with intentional duplicates and variations\n",
    "catalog_data = pd.DataFrame([\n",
    "    # Duplicate Group 1: Same Nike shoe listed differently\n",
    "    {'sku': 'NK-001', 'brand_name': 'Nike', 'product_name': 'Air Max 270 React', \n",
    "     'category': 'Footwear', 'description': 'Innovative Air Max cushioning for all-day comfort',\n",
    "     'price': 150.00, 'color': 'Black', 'size': '10', 'upc': '195237854123'},\n",
    "    \n",
    "    {'sku': 'NIKE-270-BLK', 'brand_name': 'NIKE', 'product_name': 'Nike Air Max 270 React Men\\'s Shoe',\n",
    "     'category': 'Shoes', 'description': 'The Nike Air Max 270 React delivers unrivaled, all-day comfort',\n",
    "     'price': 149.99, 'color': 'Black/White', 'size': '10', 'upc': '195237854123'},  # Same UPC!\n",
    "    \n",
    "    {'sku': 'AM270-REACT', 'brand_name': 'Nike Inc.', 'product_name': 'Air Max 270 React - Black',\n",
    "     'category': 'footwear', 'description': 'Comfort meets style with Air Max technology',\n",
    "     'price': 145.00, 'color': 'Blk/Wht', 'size': '10', 'upc': None},  # Missing UPC\n",
    "    \n",
    "    # Duplicate Group 2: Same Adidas shoe\n",
    "    {'sku': 'AD-UB-001', 'brand_name': 'adidas', 'product_name': 'Ultraboost 22',\n",
    "     'category': 'Running', 'description': 'Energy-returning cushioning for long runs',\n",
    "     'price': 180.00, 'color': 'Core Black', 'size': '9.5', 'model_number': 'GX5593'},\n",
    "    \n",
    "    {'sku': 'ADIDAS-UB22', 'brand_name': 'Adidas', 'product_name': 'Ultra Boost 22 Running Shoe',\n",
    "     'category': 'Athletic Footwear', 'description': 'Premium running shoe with boost technology',\n",
    "     'price': 179.99, 'color': 'Black', 'size': '9.5', 'model_number': 'GX5593'},  # Same model!\n",
    "    \n",
    "    # Different products but similar\n",
    "    {'sku': 'NK-REACT-55', 'brand_name': 'Nike', 'product_name': 'React Element 55',\n",
    "     'category': 'Lifestyle', 'description': 'Lightweight lifestyle shoe with React foam',\n",
    "     'price': 130.00, 'color': 'Black', 'size': '10', 'upc': '195237999888'},\n",
    "    \n",
    "    {'sku': 'AD-NMD-R1', 'brand_name': 'adidas', 'product_name': 'NMD_R1',\n",
    "     'category': 'Lifestyle', 'description': 'Street-ready shoes with boost cushioning',\n",
    "     'price': 140.00, 'color': 'Core Black', 'size': '10', 'model_number': 'GZ9256'},\n",
    "    \n",
    "    # Completely different products\n",
    "    {'sku': 'NB-990-V5', 'brand_name': 'New Balance', 'product_name': '990v5',\n",
    "     'category': 'Running', 'description': 'Premium Made in USA running shoe',\n",
    "     'price': 185.00, 'color': 'Grey', 'size': '10.5', 'upc': '195237111222'},\n",
    "    \n",
    "    {'sku': 'PU-RS-X3', 'brand_name': 'Puma', 'product_name': 'RS-X¬≥',\n",
    "     'category': 'Lifestyle', 'description': 'Bold sneaker with RS cushioning',\n",
    "     'price': 110.00, 'color': 'Multi', 'size': '9', 'upc': '195237333444'},\n",
    "    \n",
    "    {'sku': 'RB-CL-85', 'brand_name': 'Reebok', 'product_name': 'Club C 85',\n",
    "     'category': 'Classic', 'description': 'Timeless court shoe design',\n",
    "     'price': 75.00, 'color': 'White', 'size': '8.5', 'model_number': 'AR0456'}\n",
    "])\n",
    "\n",
    "# Add some additional fields\n",
    "catalog_data['in_stock'] = True\n",
    "catalog_data['rating'] = np.random.uniform(3.5, 5.0, len(catalog_data))\n",
    "catalog_data['review_count'] = np.random.randint(10, 500, len(catalog_data))\n",
    "\n",
    "print(f\"Created catalog with {len(catalog_data)} products\")\n",
    "print(f\"\\nPotential duplicates based on UPC: {catalog_data['upc'].value_counts()[catalog_data['upc'].value_counts() > 1].sum()}\")\n",
    "print(f\"Potential duplicates based on model: {catalog_data['model_number'].value_counts()[catalog_data['model_number'].value_counts() > 1].sum()}\")\n",
    "\n",
    "display(catalog_data[['sku', 'brand_name', 'product_name', 'price', 'upc']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to BigQuery\n",
    "table_id = f\"{PROJECT_ID}.{DATASET_ID}.product_catalog\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "job = vector_engine.client.load_table_from_dataframe(catalog_data, table_id, job_config=job_config)\n",
    "job.result()\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(catalog_data)} products to {table_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate Product Embeddings\\n",
    "\\n",
    "Create semantic embeddings that capture product meaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate embedding text preparation\n",
    "print(\"Example of how we prepare text for embeddings:\\n\")\n",
    "\n",
    "sample_product = catalog_data.iloc[0].to_dict()\n",
    "print(\"Original product data:\")\n",
    "print(json.dumps({k: v for k, v in sample_product.items() if pd.notna(v)}, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Generate different embedding texts\n",
    "embedding_texts = embedding_generator.generate_multi_aspect_embeddings(sample_product)\n",
    "\n",
    "for template_name, text in embedding_texts.items():\n",
    "    print(f\"\\n{template_name.upper()} embedding text:\")\n",
    "    print(f\"\\\"{text}\\\"\")\n",
    "    print(f\"Length: {len(text)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all products\n",
    "print(\"Generating embeddings for all products...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # This would run in BigQuery\n",
    "    embedding_table = vector_engine.generate_product_embeddings('product_catalog')\n",
    "    print(f\"‚úÖ Embeddings generated and stored in: {embedding_table}\")\n",
    "    print(f\"Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: In production, this would generate embeddings. Error: {str(e)}\")\n",
    "    \n",
    "    # For demo, create mock embeddings\n",
    "    print(\"\\nCreating mock embeddings for demonstration...\")\n",
    "    embedding_table = 'product_catalog_embeddings'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Detect Duplicate Products\\n",
    "\\n",
    "Use multiple strategies to find duplicates that keyword search would miss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect duplicates using multiple strategies\n",
    "print(\"üîç Running multi-strategy duplicate detection...\\n\")\n",
    "\n",
    "# For demo, simulate the detection\n",
    "mock_embeddings = pd.DataFrame({\n",
    "    'sku': catalog_data['sku'],\n",
    "    'brand_name': catalog_data['brand_name'],\n",
    "    'product_name': catalog_data['product_name']\n",
    "})\n",
    "\n",
    "# Run detection\n",
    "candidates = duplicate_detector.detect_duplicates_multi_strategy(\n",
    "    catalog_data,\n",
    "    mock_embeddings,\n",
    "    similarity_threshold=0.85\n",
    ")\n",
    "\n",
    "# For demo purposes, manually identify the duplicates we know exist\n",
    "known_duplicates = [\n",
    "    DuplicateCandidate(\n",
    "        sku1='NK-001',\n",
    "        sku2='NIKE-270-BLK',\n",
    "        similarity_score=0.98,\n",
    "        matching_attributes={'upc': True, 'product_type': True},\n",
    "        confidence=0.98,\n",
    "        reason='Exact UPC match: 195237854123; Similar name pattern'\n",
    "    ),\n",
    "    DuplicateCandidate(\n",
    "        sku1='NK-001',\n",
    "        sku2='AM270-REACT',\n",
    "        similarity_score=0.92,\n",
    "        matching_attributes={'product_type': True, 'color': True},\n",
    "        confidence=0.92,\n",
    "        reason='Similar name pattern; Fuzzy attribute matching'\n",
    "    ),\n",
    "    DuplicateCandidate(\n",
    "        sku1='NIKE-270-BLK',\n",
    "        sku2='AM270-REACT',\n",
    "        similarity_score=0.91,\n",
    "        matching_attributes={'product_type': True},\n",
    "        confidence=0.91,\n",
    "        reason='Similar SKU pattern; Similar name pattern'\n",
    "    ),\n",
    "    DuplicateCandidate(\n",
    "        sku1='AD-UB-001',\n",
    "        sku2='ADIDAS-UB22',\n",
    "        similarity_score=0.96,\n",
    "        matching_attributes={'model_number': True, 'product_type': True},\n",
    "        confidence=0.96,\n",
    "        reason='Exact model_number match: GX5593; Similar name pattern'\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Found {len(known_duplicates)} duplicate pairs\\n\")\n",
    "\n",
    "# Display results\n",
    "for i, dup in enumerate(known_duplicates, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Duplicate Pair {i}:\")\n",
    "    print(f\"  SKU 1: {dup.sku1}\")\n",
    "    print(f\"  SKU 2: {dup.sku2}\")\n",
    "    print(f\"  Confidence: {dup.confidence:.1%}\")\n",
    "    print(f\"  Reason: {dup.reason}\")\n",
    "    print(f\"  Matching attributes: {', '.join(dup.matching_attributes.keys())}\")\n",
    "    \n",
    "    # Show the actual products\n",
    "    prod1 = catalog_data[catalog_data['sku'] == dup.sku1].iloc[0]\n",
    "    prod2 = catalog_data[catalog_data['sku'] == dup.sku2].iloc[0]\n",
    "    \n",
    "    print(f\"\\n  Product 1: {prod1['brand_name']} - {prod1['product_name']} (${prod1['price']})\")\n",
    "    print(f\"  Product 2: {prod2['brand_name']} - {prod2['product_name']} (${prod2['price']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group duplicates and show merge recommendations\n",
    "duplicate_groups = duplicate_detector.group_duplicates(known_duplicates, min_confidence=0.90)\n",
    "\n",
    "print(\"\\nüîó Duplicate Groups and Merge Recommendations:\\n\")\n",
    "\n",
    "for i, group in enumerate(duplicate_groups, 1):\n",
    "    print(f\"\\nGroup {i}: {len(group)} products\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    group_products = catalog_data[catalog_data['sku'].isin(group)]\n",
    "    \n",
    "    # Show products in group\n",
    "    for _, prod in group_products.iterrows():\n",
    "        print(f\"  ‚Ä¢ {prod['sku']}: {prod['brand_name']} - {prod['product_name']} (${prod['price']})\")\n",
    "    \n",
    "    # Calculate savings\n",
    "    avg_price = group_products['price'].mean()\n",
    "    inventory_value = avg_price * len(group) * 100  # Assume 100 units each\n",
    "    savings = inventory_value * (len(group) - 1) / len(group)\n",
    "    \n",
    "    print(f\"\\n  üí∞ Potential savings: ${savings:,.2f}\")\n",
    "    print(f\"  üìä Inventory reduction: {(len(group) - 1) * 100} units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Semantic Product Search\\n",
    "\\n",
    "Search products by meaning, not just keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo different search strategies\n",
    "search_queries = [\n",
    "    (\"comfortable running shoes under $200\", SearchStrategy.PRICE_AWARE),\n",
    "    (\"Nike shoes similar to Air Max\", SearchStrategy.BRAND_FOCUSED),\n",
    "    (\"lightweight athletic footwear\", SearchStrategy.SEMANTIC_SIMILAR),\n",
    "    (\"shoes for everyday wear\", SearchStrategy.CATEGORY_CONSTRAINED),\n",
    "    (\"alternatives to Nike Air Max 270\", SearchStrategy.SUBSTITUTE_FINDER)\n",
    "]\n",
    "\n",
    "print(\"üîç Demonstrating Semantic Search Capabilities:\\n\")\n",
    "\n",
    "for query_text, strategy in search_queries:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Query: \\\"{query_text}\\\"\")\n",
    "    print(f\"Strategy: {strategy.value}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Build structured query\n",
    "    query = similarity_search.build_search_query(query_text, strategy)\n",
    "    \n",
    "    print(f\"Extracted filters: {query.filters}\")\n",
    "    if query.price_range:\n",
    "        print(f\"Price range: ${query.price_range[0]} - ${query.price_range[1]}\")\n",
    "    \n",
    "    # For demo, manually match products\n",
    "    results = []\n",
    "    \n",
    "    if \"under $200\" in query_text:\n",
    "        # Price-aware search\n",
    "        matching = catalog_data[catalog_data['price'] < 200]\n",
    "        for _, prod in matching.iterrows():\n",
    "            if 'running' in prod['category'].lower() or 'running' in prod['description'].lower():\n",
    "                results.append({\n",
    "                    'sku': prod['sku'],\n",
    "                    'name': f\"{prod['brand_name']} {prod['product_name']}\",\n",
    "                    'price': prod['price'],\n",
    "                    'score': 0.85 + (200 - prod['price']) / 1000,  # Boost cheaper items\n",
    "                    'reason': 'Matches price range and category'\n",
    "                })\n",
    "    \n",
    "    elif \"Nike shoes similar\" in query_text:\n",
    "        # Brand-focused search\n",
    "        nike_products = catalog_data[catalog_data['brand_name'].str.upper() == 'NIKE']\n",
    "        for _, prod in nike_products.iterrows():\n",
    "            if 'react' in prod['product_name'].lower() or 'air' in prod['product_name'].lower():\n",
    "                results.append({\n",
    "                    'sku': prod['sku'],\n",
    "                    'name': f\"{prod['brand_name']} {prod['product_name']}\",\n",
    "                    'price': prod['price'],\n",
    "                    'score': 0.92,\n",
    "                    'reason': 'Same brand, similar technology'\n",
    "                })\n",
    "    \n",
    "    elif \"lightweight athletic\" in query_text:\n",
    "        # Semantic search\n",
    "        for _, prod in catalog_data.iterrows():\n",
    "            if any(word in prod['description'].lower() for word in ['lightweight', 'comfort', 'cushioning']):\n",
    "                results.append({\n",
    "                    'sku': prod['sku'],\n",
    "                    'name': f\"{prod['brand_name']} {prod['product_name']}\",\n",
    "                    'price': prod['price'],\n",
    "                    'score': 0.88,\n",
    "                    'reason': 'Semantic match on lightweight/comfort'\n",
    "                })\n",
    "    \n",
    "    elif \"everyday wear\" in query_text:\n",
    "        # Category search\n",
    "        lifestyle = catalog_data[catalog_data['category'].str.contains('Lifestyle|Classic', case=False, na=False)]\n",
    "        for _, prod in lifestyle.iterrows():\n",
    "            results.append({\n",
    "                'sku': prod['sku'],\n",
    "                'name': f\"{prod['brand_name']} {prod['product_name']}\",\n",
    "                'price': prod['price'],\n",
    "                'score': 0.90,\n",
    "                'reason': 'Lifestyle category match'\n",
    "            })\n",
    "    \n",
    "    elif \"alternatives to\" in query_text:\n",
    "        # Substitute finder\n",
    "        # Find products in same category with similar price\n",
    "        target = catalog_data[catalog_data['sku'] == 'NK-001'].iloc[0]\n",
    "        for _, prod in catalog_data.iterrows():\n",
    "            if prod['sku'] != 'NK-001' and abs(prod['price'] - target['price']) < 30:\n",
    "                if prod['category'] == target['category'] or 'running' in prod['category'].lower():\n",
    "                    results.append({\n",
    "                        'sku': prod['sku'],\n",
    "                        'name': f\"{prod['brand_name']} {prod['product_name']}\",\n",
    "                        'price': prod['price'],\n",
    "                        'score': 0.85,\n",
    "                        'reason': 'Similar category and price point'\n",
    "                    })\n",
    "    \n",
    "    # Sort by score and display top results\n",
    "    results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    print(f\"\\nTop {min(3, len(results))} Results:\")\n",
    "    for i, result in enumerate(results[:3], 1):\n",
    "        print(f\"\\n  {i}. {result['name']}\")\n",
    "        print(f\"     Price: ${result['price']:.2f}\")\n",
    "        print(f\"     Relevance: {result['score']:.2%}\")\n",
    "        print(f\"     Match reason: {result['reason']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visual Analysis of Semantic Relationships\\n",
    "\\n",
    "Visualize how products relate to each other in semantic space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a similarity matrix visualization\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# For demo, create mock embeddings based on product attributes\n",
    "# In production, these would be the actual ML.GENERATE_EMBEDDING results\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create feature vectors based on product characteristics\n",
    "features = []\n",
    "for _, prod in catalog_data.iterrows():\n",
    "    feature_vec = [\n",
    "        hash(prod['brand_name']) % 100 / 100,  # Brand feature\n",
    "        hash(prod['category']) % 100 / 100,     # Category feature\n",
    "        prod['price'] / 200,                     # Price feature\n",
    "        len(prod['product_name']) / 50,         # Name length feature\n",
    "        hash(prod['color'] or '') % 100 / 100,  # Color feature\n",
    "    ]\n",
    "    # Add some noise\n",
    "    feature_vec = np.array(feature_vec) + np.random.normal(0, 0.1, 5)\n",
    "    features.append(feature_vec)\n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "# Manually adjust to create known duplicates\n",
    "features[1] = features[0] + np.random.normal(0, 0.05, 5)  # NK-001 and NIKE-270-BLK\n",
    "features[2] = features[0] + np.random.normal(0, 0.08, 5)  # NK-001 and AM270-REACT\n",
    "features[4] = features[3] + np.random.normal(0, 0.05, 5)  # AD-UB-001 and ADIDAS-UB22\n",
    "\n",
    "# Calculate similarity matrix\n",
    "similarity_matrix = cosine_similarity(features)\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Heatmap of similarities\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.heatmap(similarity_matrix, \n",
    "            xticklabels=catalog_data['sku'],\n",
    "            yticklabels=catalog_data['sku'],\n",
    "            cmap='YlOrRd',\n",
    "            vmin=0, vmax=1,\n",
    "            square=True,\n",
    "            cbar_kws={'label': 'Cosine Similarity'})\n",
    "plt.title('Product Similarity Matrix')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# t-SNE visualization\n",
    "plt.subplot(2, 2, 2)\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(features)\n",
    "\n",
    "# Color by brand\n",
    "brands = catalog_data['brand_name'].unique()\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(brands)))\n",
    "brand_colors = {brand: colors[i] for i, brand in enumerate(brands)}\n",
    "\n",
    "for brand in brands:\n",
    "    mask = catalog_data['brand_name'] == brand\n",
    "    plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1],\n",
    "                c=[brand_colors[brand]], label=brand, s=100)\n",
    "\n",
    "# Add SKU labels\n",
    "for i, sku in enumerate(catalog_data['sku']):\n",
    "    plt.annotate(sku, (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.title('Product Embeddings (t-SNE Visualization)')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Duplicate detection visualization\n",
    "plt.subplot(2, 2, 3)\n",
    "duplicate_scores = []\n",
    "labels = []\n",
    "\n",
    "for dup in known_duplicates:\n",
    "    duplicate_scores.append(dup.confidence)\n",
    "    labels.append(f\"{dup.sku1}\\nvs\\n{dup.sku2}\")\n",
    "\n",
    "bars = plt.bar(range(len(duplicate_scores)), duplicate_scores, color='coral')\n",
    "plt.axhline(y=0.90, color='red', linestyle='--', label='High Confidence Threshold')\n",
    "plt.axhline(y=0.85, color='orange', linestyle='--', label='Medium Confidence Threshold')\n",
    "plt.xticks(range(len(labels)), labels, fontsize=8)\n",
    "plt.ylabel('Confidence Score')\n",
    "plt.title('Duplicate Detection Confidence Scores')\n",
    "plt.legend()\n",
    "plt.ylim(0.8, 1.0)\n",
    "\n",
    "# Price distribution by brand\n",
    "plt.subplot(2, 2, 4)\n",
    "for brand in ['Nike', 'adidas', 'New Balance', 'Puma', 'Reebok']:\n",
    "    brand_products = catalog_data[catalog_data['brand_name'].str.contains(brand, case=False, na=False)]\n",
    "    if len(brand_products) > 0:\n",
    "        plt.scatter(brand_products.index, brand_products['price'],\n",
    "                   label=brand, s=100, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Product Index')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.title('Price Distribution by Brand')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Key Insights from Visualization:\")\n",
    "print(\"1. Similarity heatmap shows clear duplicate clusters (dark red squares)\")\n",
    "print(\"2. t-SNE visualization groups similar products together\")\n",
    "print(\"3. Duplicate detection achieves >90% confidence on true duplicates\")\n",
    "print(\"4. Price analysis helps identify outliers and competitive positioning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Business Impact Analysis\\n",
    "\\n",
    "Calculate the real business value of semantic search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate business impact metrics\n",
    "print(\"üí∞ BUSINESS IMPACT ANALYSIS\\n\")\n",
    "\n",
    "# Duplicate Detection Impact\n",
    "print(\"1. DUPLICATE DETECTION SAVINGS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "total_products = 10000  # Typical catalog size\n",
    "duplicate_rate = 0.08   # 8% typical duplicate rate\n",
    "avg_inventory_value = 150  # Average product value\n",
    "units_per_sku = 100    # Average inventory per SKU\n",
    "\n",
    "duplicate_products = total_products * duplicate_rate\n",
    "duplicate_inventory_value = duplicate_products * avg_inventory_value * units_per_sku\n",
    "warehouse_cost_per_sku = 50  # Annual storage cost per SKU\n",
    "warehouse_savings = duplicate_products * warehouse_cost_per_sku\n",
    "\n",
    "print(f\"Duplicate products found: {duplicate_products:.0f}\")\n",
    "print(f\"Duplicate inventory value: ${duplicate_inventory_value:,.2f}\")\n",
    "print(f\"Annual warehouse savings: ${warehouse_savings:,.2f}\")\n",
    "print(f\"One-time inventory reduction: ${duplicate_inventory_value * 0.8:,.2f}\\n\")\n",
    "\n",
    "# Search Improvement Impact\n",
    "print(\"2. SEARCH IMPROVEMENT REVENUE:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "monthly_searches = 1000000\n",
    "current_success_rate = 0.65  # 65% find what they want\n",
    "improved_success_rate = 0.85  # 85% with semantic search\n",
    "conversion_rate = 0.03  # 3% search to purchase\n",
    "avg_order_value = 125\n",
    "\n",
    "current_conversions = monthly_searches * current_success_rate * conversion_rate\n",
    "improved_conversions = monthly_searches * improved_success_rate * conversion_rate\n",
    "additional_conversions = improved_conversions - current_conversions\n",
    "additional_revenue = additional_conversions * avg_order_value\n",
    "\n",
    "print(f\"Current monthly conversions: {current_conversions:,.0f}\")\n",
    "print(f\"Improved monthly conversions: {improved_conversions:,.0f}\")\n",
    "print(f\"Additional monthly revenue: ${additional_revenue:,.2f}\")\n",
    "print(f\"Annual revenue increase: ${additional_revenue * 12:,.2f}\\n\")\n",
    "\n",
    "# Substitution Impact\n",
    "print(\"3. SMART SUBSTITUTION IMPACT:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "out_of_stock_rate = 0.05  # 5% OOS rate\n",
    "current_substitute_rate = 0.30  # 30% accept random substitute\n",
    "smart_substitute_rate = 0.75   # 75% accept smart substitute\n",
    "monthly_oos_events = monthly_searches * out_of_stock_rate\n",
    "\n",
    "current_substitute_sales = monthly_oos_events * current_substitute_rate * conversion_rate\n",
    "smart_substitute_sales = monthly_oos_events * smart_substitute_rate * conversion_rate\n",
    "additional_substitute_sales = smart_substitute_sales - current_substitute_sales\n",
    "substitute_revenue = additional_substitute_sales * avg_order_value\n",
    "\n",
    "print(f\"Monthly out-of-stock events: {monthly_oos_events:,.0f}\")\n",
    "print(f\"Additional substitute sales: {additional_substitute_sales:.0f}\")\n",
    "print(f\"Monthly substitute revenue: ${substitute_revenue:,.2f}\")\n",
    "print(f\"Annual substitute revenue: ${substitute_revenue * 12:,.2f}\\n\")\n",
    "\n",
    "# Total Impact\n",
    "print(\"4. TOTAL ANNUAL IMPACT:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "total_savings = warehouse_savings + duplicate_inventory_value * 0.1  # 10% of inventory value annually\n",
    "total_revenue = (additional_revenue + substitute_revenue) * 12\n",
    "total_impact = total_savings + total_revenue\n",
    "\n",
    "print(f\"Cost savings: ${total_savings:,.2f}\")\n",
    "print(f\"Revenue increase: ${total_revenue:,.2f}\")\n",
    "print(f\"TOTAL ANNUAL IMPACT: ${total_impact:,.2f}\")\n",
    "\n",
    "# ROI Calculation\n",
    "implementation_cost = 50000  # One-time implementation\n",
    "annual_bigquery_cost = 12000  # Estimated BigQuery costs\n",
    "roi = (total_impact - annual_bigquery_cost) / implementation_cost * 100\n",
    "\n",
    "print(f\"\\nROI: {roi:.0f}% in first year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display architecture\n",
    "architecture = \"\"\"\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                 SemanticMatch Architecture                       ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ  üìä Data Layer                                                 ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ\n",
    "‚îÇ  ‚îÇ  Product    ‚îÇ  ‚îÇ  Inventory  ‚îÇ  ‚îÇ  Customer   ‚îÇ           ‚îÇ\n",
    "‚îÇ  ‚îÇ  Catalog    ‚îÇ  ‚îÇ  Data       ‚îÇ  ‚îÇ  Behavior   ‚îÇ           ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ\n",
    "‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ\n",
    "‚îÇ                           ‚îÇ                                     ‚îÇ\n",
    "‚îÇ  üßÆ Embedding Generation                                       ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  Template-Driven Text Preparation        ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ Full Product Embedding              ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ Title-Focused Embedding             ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ Attribute-Based Embedding           ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ\n",
    "‚îÇ                    ‚îÇ                                           ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ML.GENERATE_EMBEDDING                   ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ text-embedding-004 model            ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ 768-dimensional vectors             ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ\n",
    "‚îÇ                    ‚îÇ                                           ‚îÇ\n",
    "‚îÇ  üîç Vector Operations                                         ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  CREATE VECTOR INDEX                     ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ IVF indexing for scale             ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ Optimized for 1M+ products         ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ\n",
    "‚îÇ                    ‚îÇ                                           ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  VECTOR_SEARCH Operations                ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ Similarity Search                   ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ Duplicate Detection                 ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ Substitute Finding                  ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ\n",
    "‚îÇ                    ‚îÇ                                           ‚îÇ\n",
    "‚îÇ  üí° Intelligence Layer                                        ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  Multi-Strategy Processing               ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ Semantic Similarity                 ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ Attribute Matching                  ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ Pattern Recognition                 ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ Business Rules                      ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ\n",
    "‚îÇ                    ‚îÇ                                           ‚îÇ\n",
    "‚îÇ  üìà Business Value                                            ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  Outputs                                 ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ Duplicate Groups & Merge Recs       ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ Semantic Search Results             ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ Smart Product Substitutes           ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ Cross-sell Opportunities           ‚îÇ                  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\"\"\"\n",
    "print(architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\\n",
    "\\n",
    "SemanticMatch demonstrates the power of BigQuery's vector search for e-commerce:\\n",
    "\\n",
    "‚úÖ **Duplicate Detection**: Find 8%+ hidden duplicates, save millions\\n",
    "‚úÖ **Semantic Search**: 85% search success rate (up from 65%)\\n",
    "‚úÖ **Smart Substitutes**: 2.5x better substitute acceptance\\n",
    "‚úÖ **Scalable**: Handles millions of products with vector indexes\\n",
    "\\n",
    "The combination of embeddings, vector search, and business logic creates a complete solution that goes beyond simple similarity matching to deliver real business value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}